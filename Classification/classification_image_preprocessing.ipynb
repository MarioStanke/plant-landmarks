{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#the following three imports have to be installed\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import Utilities.affine_math_functions as amf\n",
    "import Utilities.preprocessing_functions as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTSIZE = (105, 75)\n",
    "\n",
    "SCALE_WIDTH_CM = 2. # width in cm between the two outer scale points\n",
    "SCALE_PADDING_FACTOR = 1.4 # factor to widen the width of the box \n",
    "                           # in relation to the distance between the scale points.\n",
    "    \n",
    "                           # Without padding, the scale points show a distance of 2cm.\n",
    "                           # However, the scales are drawn at least 0.4cm longer on each side.\n",
    "                           # Due to padding, the box has a width of 2.8cm = 1.4*2cm.\n",
    "\n",
    "NUM_SEGMENTS = 3     # An odd-numbered number of segments that determines which parts are being cut.\n",
    "                     # The segments overlie one another to 50%.   \n",
    "\n",
    "# Extra Augmentationen:\n",
    "NUM_TRANSLATIONS = 9 # Number of random tranlations that are applied to each segment\n",
    "TRANSLATION_DELTA = 30   # Translations are randomly selected out of the interval\n",
    "                         # [-TRANSLATION_DELTA, TRANSLATION_DELTA]\n",
    "                       \n",
    "SCALE_PATH = '../all_scale_data.npy'\n",
    "INFOLDER = '../DIP_images_fresh/all/'\n",
    "OUTFOLDER = f\"images/images_classification/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all files and folder exist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if SCALE_PATH exists, if not raise an error to request the existance.\n",
    "if not os.path.exists(SCALE_PATH):\n",
    "    raise FileNotFoundError('The SCALE_PATH has to exist in order to start the preprocessing. Please create the file via get_scale_data.ipynb first or correct the SCALE_PATH.')\n",
    "\n",
    "#check if the INFOLDER exists, if not: raise an error to request the existence of the folder\n",
    "if not os.path.exists(INFOLDER):\n",
    "    raise FileNotFoundError('The INFOLDER has to exist with all 666 images included in order to start the preprocessing.') \n",
    "\n",
    "#check if the OUTFOLDER exists, if not: create the directory\n",
    "if not os.path.exists(OUTFOLDER):\n",
    "    os.mkdir(OUTFOLDER)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_data = np.load(SCALE_PATH, allow_pickle = True)\n",
    "scale_data = scale_data[()]\n",
    "inpaths = glob.glob(INFOLDER + '*.jpg')\n",
    "\n",
    "outratio = OUTSIZE[0]/OUTSIZE[1]       \n",
    "n = len(inpaths)   \n",
    "# Randomly chosen translations for x- and y-coordinates\n",
    "translations = np.random.randint(low=-TRANSLATION_DELTA,high=TRANSLATION_DELTA, size = (n,NUM_TRANSLATIONS,2))\n",
    "transformed_landmarks = {}\n",
    "\n",
    "for i in tqdm(range(n, desc = \"Preprocess images\", unit= \"images\"):  \n",
    "    inpath = inpaths[i]\n",
    "    filename = inpath[len(INFOLDER):]\n",
    "    img = Image.open(inpath)\n",
    "    \n",
    "    a1, m1 = pf.affine_rotation_from_scale_data(img.size, scale_data[filename])\n",
    "    cropped, box = pf.crop_from_scale_affinity(img, a1, m1, scale_data[filename], SCALE_PADDING_FACTOR)\n",
    "    a2, m2_local, reg_data = pf.affine_rotation_from_scale_data_crop(cropped)\n",
    "    \n",
    "    # Calculate the left_middle point of the shoot for segmentation\n",
    "    #Therefore, get the scale points and replicate steps from above\n",
    "    l = np.array(scale_data[filename]['left'])\n",
    "    r = np.array(scale_data[filename]['right'])\n",
    "    l[1] = img.height-l[1]\n",
    "    r[1] = img.height-r[1] \n",
    "    \n",
    "    sd = np.array([ [l[0], l[1]], [r[0], r[1]] ])\n",
    "    sd_rotated = amf.affine_rotation(a1, m1, sd)\n",
    "    lnew = sd_rotated[0,:]\n",
    "    rnew = sd_rotated[1,:]\n",
    "    # Calculate the distance \n",
    "    v = rnew - lnew\n",
    "    # Widen the width\n",
    "    lnew = lnew - (SCALE_PADDING_FACTOR - 1)/2*v\n",
    "    \n",
    "    # local coordinates in the box\n",
    "    lnew = lnew - np.array(box[:2])\n",
    "    \n",
    "    # get local coordinate of the middle of the shoot with the regression data\n",
    "    lnew[1] = reg_data[0][0]*lnew[0] + reg_data[1]\n",
    "    \n",
    "    # Transform to global rotated coordinate system\n",
    "    lnew = lnew + np.array(box[:2])\n",
    "    \n",
    "    # Transform to coordinates in the global original system\n",
    "    lnew = np.array(lnew).reshape((1,2))\n",
    "    left_middle = amf.inverse_affine_rotation(a1,m1,lnew)\n",
    "    \n",
    "    #Add both angles\n",
    "    angle = a1 + a2\n",
    "    #Calculate relation of pixels to cm \n",
    "    box_width_in_cm = SCALE_PADDING_FACTOR * SCALE_WIDTH_CM\n",
    "    cm_pixel_ratio = (box[2] - box[0]) / box_width_in_cm #x/2.8 = 1cm\n",
    "\n",
    "    #get middle of the image\n",
    "    middle_image = np.array(img.size) / 2\n",
    "    \n",
    "    #rotate the image\n",
    "    img = img.rotate(angle)\n",
    "    \n",
    "    #get the wanted left_middle point\n",
    "    left_middle = amf.affine_rotation(angle, middle_image, left_middle).flatten()\n",
    "    \n",
    "    # determine the width and height of a segment in cm \n",
    "    cm_width = SCALE_PADDING_FACTOR * SCALE_WIDTH_CM / ( (NUM_SEGMENTS-1) / 2 + 1 )\n",
    "    cm_height = cm_width / outratio \n",
    "    \n",
    "    #calculate the box for each segment\n",
    "    for s in range(NUM_SEGMENTS):\n",
    "    \n",
    "        w_left = np.array([s*cm_pixel_ratio * cm_width / 2, -(cm_pixel_ratio*cm_height/2)])\n",
    "        w_right = np.array([w_left[0] + cm_pixel_ratio * cm_width , -w_left[1]])\n",
    "\n",
    "        left = left_middle + w_left \n",
    "        right = left_middle + w_right\n",
    "\n",
    "        #get translations\n",
    "        T = np.array(np.r_[np.matrix(((0,0))), translations[i,...]])\n",
    "        \n",
    "        #apply all translations on each segment\n",
    "        for t in range(NUM_TRANSLATIONS+1):\n",
    "            translation = T[t,:]\n",
    "\n",
    "            left_t = left + translation\n",
    "            right_t = right + translation\n",
    "\n",
    "            box = (left_t[0],left_t[1],right_t[0],right_t[1]) #determine the final box\n",
    "\n",
    "            cropped = img.crop(box) #crop the image\n",
    "\n",
    "            cropped = cropped.resize(OUTSIZE) #resize the image\n",
    "\n",
    "            filename_t = filename[:-len(\".jpg\")] + f\"_s{s}_t{t}.jpg\"\n",
    "            cropped.save(OUTFOLDER + filename_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
