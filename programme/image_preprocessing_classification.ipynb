{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTSIZE = (105, 75)\n",
    "\n",
    "SCALE_WIDTH_CM = 2. # width in cm between the two outer scale points\n",
    "SCALE_PADDING_FACTOR = 1.4 # factor to widen the width of the box \n",
    "                           # in relation to the distance between the scale points.\n",
    "    \n",
    "                           # Without padding, the scale points show a distance of 2cm.\n",
    "                           # However, the scales are drawn at least 0.4cm longer on each side.\n",
    "                           # Due to padding, the box has a width of 2.8cm = 1.4*2cm.\n",
    "\n",
    "NUM_SEGMENTS = 3     # An odd-numbered number of segments that determines which parts are being cut.\n",
    "                     # The segments overlie one another to 50%.   \n",
    "\n",
    "# Extra Augmentationen:\n",
    "NUM_TRANSLATIONS = 9 # Number of random tranlations that are applied to each segment\n",
    "TRANSLATION_DELTA = 30   # Translations are randomly selected out of the interval\n",
    "                         # [-TRANSLATION_DELTA, TRANSLATION_DELTA]\n",
    "                       \n",
    "SCALE_PATH = 'all_scale_data.npy'\n",
    "INFOLDER = 'DIP_images_fresh/all/'\n",
    "OUTFOLDER = f\"images_classification/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate in an affine plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translation of radian measure in degree\n",
    "def rad_to_deg(rad):\n",
    "    return rad * 360 / (2*np.pi) \n",
    "\n",
    "#Translation of degree in radian measure\n",
    "def deg_to_rad(deg):\n",
    "    return deg / 360 * (2*np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the affine rotation\n",
    "$\\mathbb{A}_{\\varphi}(v) = O_{\\varphi}v + m$\n",
    "with rotationmatrix $O_{\\varphi} = \\begin{pmatrix} \\operatorname{cos}(\\varphi) & \\operatorname{sin}(\\varphi) \\\\ - \\operatorname{sin}(\\varphi) & \\operatorname{cos}(\\varphi) \\end{pmatrix}$ around the middle point $m$ on several vectors $v = \\text{points}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates coordinates of points after the rotation around the given middle by the given angle.\n",
    "def affine_rotation(angle, middle, points):\n",
    "    \n",
    "    phi = deg_to_rad(angle) #degree to radian measure\n",
    "    \n",
    "    O = np.array([[np.cos(phi), np.sin(phi)],[-np.sin(phi), np.cos(phi)]]).reshape([2,2]) #rotation matrix\n",
    "    v = points - middle\n",
    "    \n",
    "    flat = len(v.shape) == 1\n",
    "    \n",
    "    if flat:\n",
    "        v = v.reshape([1,2])\n",
    "        \n",
    "    #get new cooedinated by multiplication with rotation matrix and addition of the middle\n",
    "    result = np.einsum('ij,kj -> ki', O, v) + middle      \n",
    "    \n",
    "    if flat:\n",
    "        result = result.flatten()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the inverse affine rotation\n",
    "$\\mathbb{A}_{\\varphi}(v) = O^\\intercal_{\\varphi}v + m$\n",
    "with rotationmatrix $O^\\intercal_{\\varphi} = \\begin{pmatrix} \\operatorname{cos}(\\varphi) & -\\operatorname{sin}(\\varphi) \\\\ \\operatorname{sin}(\\varphi) & \\operatorname{cos}(\\varphi) \\end{pmatrix}$ around the middle point $m$ on several vectors $v = \\text{points}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_affine_rotation(angle, middle, points):\n",
    "    \n",
    "    phi = deg_to_rad(angle) #degree in radian measure\n",
    "    \n",
    "    O = np.array([[np.cos(phi), np.sin(phi)],[-np.sin(phi), np.cos(phi)]]).reshape([2,2]) #rotation matrix\n",
    "    v = points - middle\n",
    "    \n",
    "    flat = len(v.shape) == 1\n",
    "    \n",
    "    if flat:\n",
    "        v = v.reshape([1,2])\n",
    "        \n",
    "    #get new cooedinated by multiplication with rotation matrix and addition of the middle\n",
    "    result = np.einsum('ij,kj -> ki', O.T, v) + middle     \n",
    "    \n",
    "    if flat:\n",
    "        result = result.flatten()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the centroid s = $\\frac{1}{m}\\cdot\\sum\\limits_{i=1}^{m} x_{i} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid(points):\n",
    "    return np.mean(points, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the origin point to new_origin and update given points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_translation(new_origin, points):\n",
    "    return points - new_origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate rotanial affinity for given scale points of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_rotation_from_scale_data(img_dimension, scale_data, top_offset = 300):\n",
    "    \n",
    "    left = scale_data['left']\n",
    "    right = scale_data['right']\n",
    "    x1 = left[0]\n",
    "    y1 = left[1]\n",
    "    x2 = right[0]\n",
    "    y2 = right[1]\n",
    "    \n",
    "    l = np.array([x1,y1])\n",
    "    r = np.array([x2,y2])\n",
    "    angle = 0\n",
    "\n",
    "    if (y2 != y1):\n",
    "\n",
    "        alpha = np.arctan(np.abs(y2-y1) / np.abs(x2-x1)) #calculate the angle\n",
    "        angle = rad_to_deg(alpha) #radian measure to degree\n",
    "        angle = -np.sign(y2-y1) * angle #get sign to rotate accordingly\n",
    "\n",
    "    middle = np.array( [img_dimension[0] / 2, img_dimension[1] / 2] ) #calculate the middle of the image, \n",
    "                                                                      # because rotate function rotates \n",
    "                                                                      # around the middle point\n",
    "    return angle, middle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the above rotation to determine a box in order to cut off the clothes-pegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_from_scale_affinity(img, angle, middle, scale_data, top_offset = 300, scale_padding_factor=SCALE_PADDING_FACTOR):\n",
    "    \n",
    "    l = np.array(scale_data['left'])\n",
    "    r = np.array(scale_data['right'])\n",
    "    \n",
    "    l[1] = img.height-l[1] #get points in the scale with (0,0) in the upper left corner\n",
    "    r[1] = img.height-r[1] \n",
    "    \n",
    "    scale_data = np.array([ [l[0], l[1]], [r[0], r[1]] ])\n",
    "    scale_data_rotated = affine_rotation(angle, middle, scale_data) #get the rotated coordinates\n",
    "    lnew = scale_data_rotated[0,:]\n",
    "    rnew = scale_data_rotated[1,:]\n",
    "    \n",
    "    img = img.rotate(angle) #rotate the image \n",
    "\n",
    "    v = rnew - lnew #calculate distance between both scale points\n",
    "    lnew = lnew - (scale_padding_factor - 1)/2*v # widen the width\n",
    "    rnew = rnew + (scale_padding_factor - 1)/2*v \n",
    "    w = np.array([ v[1], -v[0] ]) #canonical choice for a vector perpendicular to v\n",
    "    ulnew = lnew + w #add w to the furthest left point\n",
    "    ulnew[1] = ulnew[1] - top_offset #increase the height such that no part of the shoot gets cut off\n",
    "\n",
    "    box = (ulnew[0],ulnew[1],rnew[0],rnew[1]) #define box\n",
    "\n",
    "    cropped = img.crop(box) #crop image\n",
    "\n",
    "    return cropped, box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine an affine rotation based on a regression over the green pixel points of a shoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_rotation_from_scale_data_crop(cropped):\n",
    "    im_rgb = cropped.convert(\"RGB\")\n",
    "    I = np.transpose(np.array(im_rgb), (1,0,2))\n",
    "    I = I.astype(np.int64)\n",
    "\n",
    "    # treshold for the colour channel in order to detect the white background\n",
    "    wlim = 10\n",
    "\n",
    "    # Determine the colour channel\n",
    "    R = I[:,:,0]\n",
    "    G = I[:,:,1]\n",
    "    B = I[:,:,2]\n",
    "\n",
    "    # Set relations of the channel to detect the white background\n",
    "    W = np.max( np.c_[ np.abs(R-G)[:,:,np.newaxis], np.abs(B-G)[:,:,np.newaxis], np.abs(R-B)[:,:,np.newaxis] ], axis=2)\n",
    "\n",
    "    # Calculate the framing mask to detect the pixels that belong to a shoot\n",
    "    J = (R <= G) & (B <= G) & (W > wlim) \n",
    "    \n",
    "    x,y = J.nonzero()\n",
    "    reg = LinearRegression(fit_intercept = True).fit(x[:,np.newaxis],y) #calculate a linear regression over all these points\n",
    "    \n",
    "    reg_coef = reg.coef_[0]\n",
    "    reg_data = (reg.coef_, reg.intercept_)\n",
    "    \n",
    "    angle = np.arctan(1 / np.abs(reg_coef)) * 180 / np.pi #calculate an angle basen on the regression coefficient\n",
    "    angle = np.sign(reg_coef) * (90-angle) #correct the sign of the angle\n",
    "    middle = np.array( [cropped.width / 2, cropped.height / 2] ) #get the middel point\n",
    "\n",
    "    return angle, middle, reg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FÃ¼r Testzwecke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, landmarks, radius = 10):\n",
    "    lm = landmarks\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i in range(lm.shape[0]):\n",
    "        draw.ellipse((lm[i,0]-radius,lm[i,1]-radius, lm[i,0]+radius,lm[i,1]+radius),fill = 'red')\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n",
      "5%\n",
      "10%\n",
      "15%\n",
      "20%\n",
      "25%\n",
      "30%\n",
      "35%\n",
      "40%\n",
      "45%\n",
      "50%\n",
      "55%\n",
      "60%\n",
      "65%\n",
      "70%\n",
      "75%\n",
      "80%\n",
      "85%\n",
      "90%\n",
      "95%\n",
      "100%\n"
     ]
    }
   ],
   "source": [
    "scale_data = np.load(SCALE_PATH, allow_pickle = True)\n",
    "scale_data = scale_data[()]\n",
    "inpaths = glob.glob(INFOLDER + '*.jpg')\n",
    "\n",
    "outratio = OUTSIZE[0]/OUTSIZE[1]       \n",
    "n = len(inpaths)   \n",
    "# Randomly chosen translations for x- and y-coordinates\n",
    "translations = np.random.randint(low=-TRANSLATION_DELTA,high=TRANSLATION_DELTA, size = (n,NUM_TRANSLATIONS,2))\n",
    "transformed_landmarks = {}\n",
    "\n",
    "DEBUG_STEPS = 5\n",
    "debug_interval = int(DEBUG_STEPS/100 * 666)\n",
    "\n",
    "for i in range(n):\n",
    "    if i % debug_interval == 0:\n",
    "        print(f\"{i // debug_interval * DEBUG_STEPS}%\")\n",
    "            \n",
    "    inpath = inpaths[i]\n",
    "    filename = inpath[len(INFOLDER):]\n",
    "    img = Image.open(inpath)\n",
    "   \n",
    "    a1, m1 = affine_rotation_from_scale_data(img.size, scale_data[filename])\n",
    "    cropped, box = crop_from_scale_affinity(img, a1, m1, scale_data[filename])\n",
    "    a2, m2_local, reg_data = affine_rotation_from_scale_data_crop(cropped)\n",
    "    \n",
    "    # Calculate the left_middle point of the shoot for segmentation\n",
    "    #Therefore, get the scale points and replicate steps from above\n",
    "    l = np.array(scale_data[filename]['left'])\n",
    "    r = np.array(scale_data[filename]['right'])\n",
    "    l[1] = img.height-l[1]\n",
    "    r[1] = img.height-r[1] \n",
    "    \n",
    "    sd = np.array([ [l[0], l[1]], [r[0], r[1]] ])\n",
    "    sd_rotated = affine_rotation(a1, m1, sd)\n",
    "    lnew = sd_rotated[0,:]\n",
    "    rnew = sd_rotated[1,:]\n",
    "    # Calculate the distance \n",
    "    v = rnew - lnew\n",
    "    # Widen the width\n",
    "    lnew = lnew - (SCALE_PADDING_FACTOR - 1)/2*v\n",
    "    \n",
    "    # local coordinates in the box\n",
    "    lnew = lnew - np.array(box[:2])\n",
    "    \n",
    "    # get local coordinate of the middle of the shoot with the regression data\n",
    "    lnew[1] = reg_data[0][0]*lnew[0] + reg_data[1]\n",
    "    \n",
    "    # Transform to global rotated coordinate system\n",
    "    lnew = lnew + np.array(box[:2])\n",
    "    \n",
    "    # Transform to coordinates in the global original system\n",
    "    lnew = np.array(lnew).reshape((1,2))\n",
    "    left_middle = inverse_affine_rotation(a1,m1,lnew)\n",
    "    \n",
    "    #Add both angles\n",
    "    angle = a1 + a2\n",
    "    #Calculate relation of pixels to cm \n",
    "    box_width_in_cm = SCALE_PADDING_FACTOR * SCALE_WIDTH_CM\n",
    "    cm_pixel_ratio = (box[2] - box[0]) / box_width_in_cm #x/2.8 = 1cm\n",
    "\n",
    "    #get middle of the image\n",
    "    middle_image = np.array(img.size) / 2\n",
    "    \n",
    "    #rotate the image\n",
    "    img = img.rotate(angle)\n",
    "    \n",
    "    #get the wanted left_middle point\n",
    "    left_middle = affine_rotation(angle, middle_image, left_middle).flatten()\n",
    "    \n",
    "    # determine the width and height of a segment in cm \n",
    "    cm_width = SCALE_PADDING_FACTOR * SCALE_WIDTH_CM / ( (NUM_SEGMENTS-1) / 2 + 1 )\n",
    "    cm_height = cm_width / outratio \n",
    "    \n",
    "    #calculate the box for each segment\n",
    "    for s in range(NUM_SEGMENTS):\n",
    "    \n",
    "        w_left = np.array([s*cm_pixel_ratio * cm_width / 2, -(cm_pixel_ratio*cm_height/2)])\n",
    "        w_right = np.array([w_left[0] + cm_pixel_ratio * cm_width , -w_left[1]])\n",
    "\n",
    "        left = left_middle + w_left \n",
    "        right = left_middle + w_right\n",
    "\n",
    "        #get translations\n",
    "        T = np.array(np.r_[np.matrix(((0,0))), translations[i,...]])\n",
    "        \n",
    "        #apply all translations on each segment\n",
    "        for t in range(NUM_TRANSLATIONS+1):\n",
    "            translation = T[t,:]\n",
    "\n",
    "            left_t = left + translation\n",
    "            right_t = right + translation\n",
    "\n",
    "            box = (left_t[0],left_t[1],right_t[0],right_t[1]) #determine the final box\n",
    "\n",
    "            cropped = img.crop(box) #crop the image\n",
    "\n",
    "            cropped = cropped.resize(OUTSIZE) #resize the image\n",
    "\n",
    "            filename_t = filename[:-len(\".jpg\")] + f\"_s{s}_t{t}.jpg\"\n",
    "            cropped.save(OUTFOLDER + filename_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
