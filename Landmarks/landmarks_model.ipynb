{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following four imports have to be installed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Reshape\n",
    "#from tensorboard.plugins.hparams import api as hp\n",
    "import pandas as pd\n",
    "\n",
    "import pandas.util\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (200,100)    # width and height of all images (resize, if required)\n",
    "BATCH_SIZE = 32  # for training and prediction\n",
    "EPOCHS = 50\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "LOG_DIR = \"logs/\"\n",
    "MODELFNAME = \"model_checkpoints/landmarks_final.h5\"\n",
    "\n",
    "TEST_PKL = \"files/test_landmarks_df.pkl\"\n",
    "TRAIN_PKL = \"files/train_landmarks_df.pkl\"\n",
    "VAL_PKL = \"files/val_landmarks_df.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the path does not exist, create it. \n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.mkdir(LOG_DIR)\n",
    "\n",
    "# If the path does not exist, create it.    \n",
    "if not os.path.exists(MODELFNAME):\n",
    "    os.mkdir(MODELFNAME)\n",
    "\n",
    "# However, if the path exists and has been used before, the content has to be deleted and the directory created again.\n",
    "if os.path.exists(LOG_DIR):\n",
    "    shutil.rmtree(LOG_DIR)\n",
    "    os.mkdir(LOG_DIR)\n",
    "    \n",
    "#check if the TEST_PKL, TRAIN_PKL, VAL_PKL files exist. If not: raise an error.\n",
    "if not os.path.exists(TEST_PKL):\n",
    "    raise FileNotFoundError('The model preprocess (landmarks_model_preprocess.ipynb) has to be conducted first or the name of the TEST_PKL has to be adjusted.')\n",
    "if not os.path.exists(TRAIN_PKL):\n",
    "    raise FileNotFoundError('The model preprocess (landmarks_model_preprocess.ipynb) has to be conducted first or the name of the IMAGE_FOLDER has to be adjusted.')\n",
    "if not os.path.exists(VAL_PKL):\n",
    "    raise FileNotFoundError('The model preprocess (landmarks_model_preprocess.ipynb) has to be conducted first or the name of the IMAGE_FOLDER has to be adjusted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get test, train, validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle(TEST_PKL)\n",
    "train_df = pd.read_pickle(TRAIN_PKL)\n",
    "val_df = pd.read_pickle(VAL_PKL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map a filename to an actual image tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_array(filename, landmarks):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_png(img, channels = 3)\n",
    "    # now img is 3 dim array of numbers in {0,..., 255}\n",
    "    img = tf.cast(img, dtype = tf.float32) / 255. \n",
    "    return img, landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a tf dataset of images from a pd data frame of file paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df):\n",
    "    # first, make dataset with just the relevant: path and landmarks\n",
    "    ds_path = tf.data.Dataset.from_tensor_slices((df['image_path'], df['landmarks']))\n",
    "\n",
    "    # convert to data set with actual images\n",
    "    ds = ds_path.map(path_to_array)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    return ds\n",
    "\n",
    "test_ds  = make_dataset(test_df)\n",
    "val_ds   = make_dataset(val_df)\n",
    "train_ds = make_dataset(train_df)\n",
    "train_ds = train_ds.repeat() # infinitely repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine architecture and parameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (3, 3)\n",
    "pool_size   = (2, 2)\n",
    "first_filters  = 32\n",
    "second_filters = 64\n",
    "third_filters  = 128\n",
    "dropout_conv  = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "model = tf.keras.models.Sequential() # sequential stack of layers\n",
    "\n",
    "model.add( BatchNormalization(input_shape = (IMG_SIZE[1],IMG_SIZE[0], 3)))\n",
    "model.add( Conv2D (first_filters, kernel_size, activation = 'relu')) #convolutional layer + activation layer\n",
    "model.add( Conv2D (first_filters, kernel_size, activation = 'relu'))\n",
    "model.add( Conv2D (first_filters, kernel_size, activation = 'relu'))\n",
    "model.add( MaxPooling2D (pool_size = pool_size)) #Pooling layer\n",
    "model.add( Dropout (dropout_conv)) # Dropout layer\n",
    "\n",
    "model.add( Conv2D (second_filters, kernel_size, activation ='relu'))\n",
    "model.add( Conv2D (second_filters, kernel_size, activation ='relu'))\n",
    "model.add( Conv2D (second_filters, kernel_size, activation ='relu'))\n",
    "model.add( MaxPooling2D (pool_size = pool_size))\n",
    "model.add( Dropout (dropout_conv))\n",
    "\n",
    "model.add( Conv2D (third_filters, kernel_size, activation ='relu'))\n",
    "model.add( Conv2D (third_filters, kernel_size, activation ='relu'))\n",
    "model.add( Conv2D (third_filters, kernel_size, activation ='relu'))\n",
    "model.add( MaxPooling2D (pool_size = pool_size))\n",
    "model.add( Dropout (dropout_conv))\n",
    "\n",
    "model.add( Flatten())\n",
    "model.add( Dense (256, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.001))) #dense layer + activation layer\n",
    "model.add( Dropout (dropout_dense)) #Dropout layer\n",
    "model.add( Dense (20))  # Dense layer\n",
    "model.add( Reshape ((10,2))) #Reshape to wanted output\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss, optimization algorithm and prepare the model for gradient computation \n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005),\n",
    "              loss = 'MSE', metrics = ['acc']) #loss = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_df)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1, update_freq='batch')\n",
    "\n",
    "# Function to store model to file, if validation loss has a new record\n",
    "# Check always after having seen at least another save_freq examples.\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    MODELFNAME, monitor = 'val_loss', mode = 'min', \n",
    "    save_best_only = True, verbose = 1)\n",
    "\n",
    "# Function to decrease learning rate by 'factor'\n",
    "# when there has been no significant improvement in the last 'patience' epochs.\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor = 'val_loss', mode = 'min', factor = 0.75, patience = 4, verbose = 1)\n",
    "                         \n",
    "# fit_generator is like fit, but training set generation (image reading) is run in parallel to optimization\n",
    "model.fit_generator(\n",
    "    train_ds, epochs = EPOCHS, \n",
    "    steps_per_epoch = num_train / BATCH_SIZE, #would use each example once on average\n",
    "    validation_data = val_ds, verbose = 1,\n",
    "    callbacks = [checkpoint, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parameters with the best validation accuracy during training.\n",
    "# This works also if you interruped the training!\n",
    "model.load_weights(MODELFNAME)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose = 0)\n",
    "print(\"Loss on test set:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a collage with predicted and original landmarks on the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "from PIL import ImageDraw\n",
    "from PIL import Image\n",
    "import ntpath\n",
    "\n",
    "all_lm = np.load('files/preprocessed_landmarks.npy', allow_pickle = True)[()].copy()\n",
    "unique_test_files = list({key[:-len(\"_t0.jpg\")] for key in test_df.filename.tolist()})\n",
    "\n",
    "columns = 5\n",
    "lm_radius = 1\n",
    "n = len(unique_test_files)\n",
    "rows = math.ceil(n / columns)\n",
    "outsize = IMG_SIZE\n",
    "\n",
    "collage = Image.new('RGB', (columns * outsize[0], rows * outsize[1]))\n",
    "\n",
    "for i in tqdm(range(n), unit='images', desc='Drawing landmarks'):\n",
    "    img_path = f\"images/images_landmarks/{unique_test_files[i]}_t0.jpg\"\n",
    "    filename = ntpath.basename(img_path)\n",
    "    \n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img, channels = 3)\n",
    "    # now img is 3 dim array of numbers in {0,..., 255}\n",
    "    img = tf.cast(img, dtype = tf.float32) / 255.\n",
    "    \n",
    "    landmarks = model(tf.expand_dims(img, 0))[0,...]\n",
    "    \n",
    "    x = (i % columns) * outsize[0]\n",
    "    y = (i // columns) * outsize[1]\n",
    "    \n",
    "    lm = landmarks\n",
    "    orig_lm = all_lm[filename][\"landmarks\"]\n",
    "    img = Image.open(img_path)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for i in range(lm.shape[0]):\n",
    "        draw.ellipse((lm[i,0]-lm_radius,lm[i,1]-lm_radius, lm[i,0]+lm_radius,lm[i,1]+lm_radius),fill = 'red')\n",
    "        draw.ellipse((orig_lm[i,0]-lm_radius,orig_lm[i,1]-lm_radius, orig_lm[i,0]+lm_radius,orig_lm[i,1]+lm_radius),fill = 'blue')\n",
    "        \n",
    "    collage.paste(img, (x, y))\n",
    "    \n",
    "\n",
    "collage.save('learned_collage_landmarks_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
