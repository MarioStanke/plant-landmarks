{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "\n",
    "#the following three imports have to be installed\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import Utilities.affine_math_functions as amf\n",
    "import Utilities.preprocessing_functions as pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTSIZE = (200, 100)\n",
    "SCALE_WIDTH_CM = 2 # width in cm between the two outer scale points\n",
    "SCALE_PADDING_FACTOR = 1.4 # factor to widen the width of the box \n",
    "                           # in relation to the distance between the scale points.\n",
    "    \n",
    "                           # Without padding, the scale points show a distance of 2cm.\n",
    "                           # However, the scales are drawn at least 0.4cm longer on each side.\n",
    "                           # Due to padding, the box has a width of 2.8cm = 1.4*2cm.\n",
    "NUM_TRANSLATIONS = 5 # Number of random tranlations that are applied to each segment\n",
    "TRANSLATION_DELTA = 30   # Translations are randomly selected out of the interval\n",
    "                         # [-TRANSLATION_DELTA, TRANSLATION_DELTA]\n",
    "\n",
    "SCALE_PATH = '../all_scale_data.npy'\n",
    "INFOLDER = '../DIP_images_fresh/all/'\n",
    "OUTFOLDER = f\"images/images_landmarks/\"\n",
    "\n",
    "LANDMARK_PATH = 'files/preprocessed_landmarks.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if all files and folder exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if SCALE_PATH exists, if not raise an error to request the existance.\n",
    "if not os.path.exists(SCALE_PATH):\n",
    "    raise FileNotFoundError('The SCALE_PATH has to exist in order to start the preprocessing. Please create the file via get_scale_data.ipynb first or correct the SCALE_PATH.')\n",
    "\n",
    "#check if the OUTFOLDER exists, if not: create the directory\n",
    "if not os.path.exists(OUTFOLDER):\n",
    "    os.mkdir(OUTFOLDER)  \n",
    "\n",
    "#check if the INFOLDER exists, if not: raise an error to request the existence of the folder\n",
    "if not os.path.exists(INFOLDER):\n",
    "    raise FileNotFoundError('The INFOLDER has to exist with all 666 images included in order to start the preprocessing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_data = np.load(SCALE_PATH, allow_pickle = True)\n",
    "scale_data = scale_data[()]\n",
    "inpaths = glob.glob(INFOLDER + '*.jpg')\n",
    "\n",
    "outratio = OUTSIZE[0]/OUTSIZE[1]\n",
    "\n",
    "n = len(inpaths)   \n",
    "# Independently identically distributed uniform random translations for x- and y-coordinates\n",
    "translations = np.random.randint(low=-TRANSLATION_DELTA,high=TRANSLATION_DELTA, size = (n,NUM_TRANSLATIONS,2))\n",
    "transformed_landmarks = {}\n",
    "\n",
    "for i in tqdm(range(n), desc = \"Preprocess images\", unit= \"images\"):\n",
    "    inpath = inpaths[i]\n",
    "    filename = inpath[len(INFOLDER):]\n",
    "    img = Image.open(inpath)\n",
    "    \n",
    "    landmarks = copy.deepcopy(scale_data[filename]['landmarks'])\n",
    "   \n",
    "    a1, m1 = pf.affine_rotation_from_scale_data(img.size, scale_data[filename])\n",
    "    cropped, box = pf.crop_from_scale_affinity(img, a1, m1, scale_data[filename], SCALE_PADDING_FACTOR)\n",
    "    a2, m2_local, reg_data = pf.affine_rotation_from_scale_data_crop(cropped)\n",
    "    \n",
    "    #add angles\n",
    "    angle = a1 + a2\n",
    "    \n",
    "    #Calculate relation of pixels to cm\n",
    "    box_width_in_cm = SCALE_PADDING_FACTOR * SCALE_WIDTH_CM\n",
    "    cm_pixel_ratio = (box[2] - box[0]) / box_width_in_cm #w/2.8 = 1cm\n",
    "    \n",
    "    #calculate centroid of landmarks and middle of the image\n",
    "    middle_landmarks = amf.centroid(landmarks)\n",
    "    middle_image = np.array(img.size) / 2\n",
    "    \n",
    "     #calculate distance between them\n",
    "    v = middle_landmarks - middle_image\n",
    "    \n",
    "    #translate middle of the image to the centoid of the landmarks\n",
    "    img = img.transform(img.size, Image.AFFINE, (1, 0, v[0], 0, 1, v[1]))\n",
    "    #rotate image\n",
    "    img = img.rotate(angle)\n",
    "\n",
    "    #update landmark coordinates after translation\n",
    "    landmarks = amf.affine_translation(v, landmarks)\n",
    "    \n",
    "    #update landmark coordinates after rotation\n",
    "    landmarks = amf.affine_rotation(angle, middle_image, landmarks)\n",
    "\n",
    "    middle_landmarks = amf.centroid(landmarks)\n",
    "\n",
    "    # determine the height of the box\n",
    "    cm_height = SCALE_WIDTH_CM * (1/outratio)\n",
    "    \n",
    "    #determine left and right points of the box\n",
    "    w_left = np.array([(cm_pixel_ratio * SCALE_WIDTH_CM/2), (cm_pixel_ratio*cm_height/2)])\n",
    "    w_right = np.array([(cm_pixel_ratio * SCALE_WIDTH_CM/2), (cm_pixel_ratio*cm_height/2)])\n",
    "    left = middle_image - w_left \n",
    "    right = middle_image + w_right\n",
    "    \n",
    "    #get translations\n",
    "    T = np.array(np.r_[np.matrix(((0,0))), translations[i,...]])\n",
    "    \n",
    "    #apply all translations on the image\n",
    "    for t in range(NUM_TRANSLATIONS+1):\n",
    "        translation = T[t,:]\n",
    "        \n",
    "        left_t = left + translation\n",
    "        right_t = right + translation\n",
    "\n",
    "        box = (left_t[0],left_t[1],right_t[0],right_t[1]) #determine the final box\n",
    "        \n",
    "        cropped = img.crop(box) #crop the image\n",
    "\n",
    "        #update landmark coordinates after cropping\n",
    "        landmarks_t = amf.affine_translation(left_t, landmarks)\n",
    "        \n",
    "        #resize cropped image\n",
    "        cropped = cropped.resize(OUTSIZE)\n",
    "        \n",
    "        #update landmark coordinates after resize\n",
    "        scaling_factor = (right_t[0]-left_t[0])/OUTSIZE[0]\n",
    "        landmarks_t = landmarks_t / scaling_factor\n",
    "        \n",
    "        filename_t = filename[:-len(\".jpg\")] + f\"_t{t}.jpg\"\n",
    "        cropped.save(OUTFOLDER + filename_t)\n",
    "        \n",
    "        transformed_landmarks[filename_t] = {\n",
    "            'landmarks' : landmarks_t\n",
    "        }\n",
    "\n",
    "np.save(LANDMARK_PATH,transformed_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
